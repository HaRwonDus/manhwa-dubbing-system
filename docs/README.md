# üé¨ AI Manhwa Dubbing System for YouTube

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![AI](https://img.shields.io/badge/AI-Powered-purple.svg)](https://www.openai.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> üöÄ A fully automated **AI pipeline** that transforms manhwa chapters into professional YouTube recap videos ‚Äî complete with emotional voice narration, intelligent summaries, and cinematic sound design.

---

## üß© Overview

The **AI Manhwa Dubbing System** automates the entire process of creating long-form manhwa recap videos for YouTube.  
It extracts text from manhwa chapters, summarizes the story using GPT-4, detects and crops panels, generates expressive TTS narration, and composes the final video ‚Äî ready for upload.

**Example Reference:** [üé• Manhwa Recap Sample](https://youtu.be/3Wjqr9wL7B0)

---

## ‚ú® Key Features

| Category | Feature | Description |
|-----------|----------|-------------|
| üñºÔ∏è OCR | Automated text extraction | Extracts dialogue and text bubbles using Tesseract OCR |
| ü§ñ AI Recap | GPT-4 story summarization | Builds coherent, engaging storylines |
| ‚úÇÔ∏è Vision | Smart panel cropping | Uses OpenCV + YOLO for precise panel segmentation |
| üéôÔ∏è Audio | Emotional text-to-speech | Natural, expressive voice narration (male/female) |
| üé¨ Video | Automated video assembly | Combines visuals, narration, and music into YouTube-ready format |
| üéµ Sound | Dynamic background soundtrack | Adds mood-matched background music |
| üß† Scalability | Parallel processing | Multi-chapter batch processing supported |

---

## üß± System Architecture

```
Input: Manhwa Chapters (Images / PDF)
    ‚Üì
[ OCR Module ] ‚Üí Extract Text + Dialogues
    ‚Üì
[ AI Recap Engine ] ‚Üí Generate Narrative Summary
    ‚Üì
[ Panel Detector ] ‚Üí Crop & Sequence Panels
    ‚Üì
[ TTS Engine ] ‚Üí Generate Voice Narration
    ‚Üì
[ Video Assembler ] ‚Üí Merge Panels, Audio & Music
    ‚Üì
Output: 2‚Äì3 Hour Dubbed Recap Video ‚Üí YouTube Upload
```

üìÑ See [`/docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) for a detailed architecture breakdown.

---

## ‚öôÔ∏è Technology Stack

| Layer | Technology | Purpose |
|--------|-------------|----------|
| Core | Python 3.9+ | Primary language |
| OCR | Tesseract, OpenCV | Text detection & extraction |
| NLP | GPT-4 API | Story summarization |
| Vision | YOLOv8 / U-Net | Panel detection |
| TTS | ElevenLabs / Coqui | Emotional voice synthesis |
| Video | MoviePy + FFmpeg | Video assembly & encoding |
| Audio | Pydub / Librosa | Music synchronization |
| Config | YAML / .env | Configuration management |

---

## üì¶ Prerequisites

```bash
# Python
Python >= 3.9

# System Dependencies
sudo apt install tesseract-ocr ffmpeg  # Linux
brew install tesseract ffmpeg          # macOS
# Windows: Install from official websites

# Required API Keys
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
```

---

## üöÄ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ai-manhwa-dubbing.git
cd ai-manhwa-dubbing
```

### 2. Setup Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```

---

## üß† Usage

### Python Interface

```python
from src.pipeline.main_pipeline import ManhwaDubbingPipeline

pipeline = ManhwaDubbingPipeline(
    input_dir="data/input/manhwa_chapters",
    output_dir="data/output"
)

pipeline.run(
    chapters_range=(1, 30),
    voice_type="female",
    voice_emotion="expressive",
    target_duration=7200  # 2 hours
)
```

### CLI Example

```bash
python src/pipeline/main_pipeline.py     --input data/input/solo_leveling     --chapters 1-30     --voice female     --emotion dramatic     --duration 7200     --output data/output/recap.mp4
```

---

## üß© Project Structure

```
manhwa-dubbing-ai/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ocr/                 # Text extraction
‚îÇ   ‚îú‚îÄ‚îÄ recap/               # GPT-4 summarization logic
‚îÇ   ‚îú‚îÄ‚îÄ tts/                 # Voice generation & emotional tone
‚îÇ   ‚îú‚îÄ‚îÄ video/               # Video assembly
‚îÇ   ‚îú‚îÄ‚îÄ audio/               # Music mixing & audio sync
‚îÇ   ‚îî‚îÄ‚îÄ pipeline/            # Orchestration & CLI
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/               # Input manhwa images
‚îÇ   ‚îú‚îÄ‚îÄ output/              # Final videos
‚îÇ   ‚îî‚îÄ‚îÄ temp/                # Temp files
‚îú‚îÄ‚îÄ config/                  # Configuration files
‚îú‚îÄ‚îÄ docs/                    # Project documentation
‚îú‚îÄ‚îÄ tests/                   # Unit tests
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üéõÔ∏è Configuration Example

`config/config.yaml`
```yaml
ocr:
  engine: tesseract
  language: eng
  preprocessing: true

recap:
  model: gpt-4
  style: engaging
  max_tokens: 8000

tts:
  provider: elevenlabs
  voice_id: Rachel
  emotion: expressive

video:
  fps: 24
  resolution: 1920x1080
  codec: h264

audio:
  background_music: true
  music_volume: 0.3
```

---

## üìä Performance

| Stage | Time per Chapter | Description |
|--------|------------------|-------------|
| OCR | 30‚Äì60 sec | Depends on image quality |
| Recap Generation | 20‚Äì40 sec | GPT-4 summarization |
| Panel Detection | 10‚Äì20 sec | GPU-accelerated |
| TTS | 2‚Äì5 min / 1000 words | Emotional synthesis |
| Video Assembly | 3‚Äì5 min | Final rendering |

üïí **Total:** ~30‚Äì40 minutes for 30 chapters (2‚Äì3 hour recap video)

---

## üß± Deployment

### Docker

```bash
docker build -t manhwa-dubbing:latest .
docker run -v $(pwd)/data:/app/data     -e OPENAI_API_KEY=$OPENAI_API_KEY     -e ELEVENLABS_API_KEY=$ELEVENLABS_API_KEY     manhwa-dubbing:latest
```

### GitHub Actions (CI/CD)

See workflow: `.github/workflows/process_video.yml`

---

## üß™ Testing

```bash
pytest tests/
pytest --cov=src
```

---

## üßë‚Äçüíª Roadmap

- [ ] Multi-language OCR (Korean, Japanese, Chinese)
- [ ] Real-time streaming mode
- [ ] Web dashboard for editing
- [ ] Character-consistent TTS voice memory
- [ ] Fully local mode (offline inference)
- [ ] Voice cloning dataset builder

---

## ‚öñÔ∏è License & Fair Use Notice

This software is provided under the **MIT License**.  
It is intended for **transformative and educational use only**.

Please ensure:
- Use excerpts, not full chapters
- Add commentary or analysis
- Credit original creators
- Respect YouTube copyright claims

---

## üôå Credits

- **Tesseract OCR** ‚Äì Optical character recognition  
- **OpenAI GPT-4** ‚Äì Story summarization  
- **ElevenLabs** ‚Äì Text-to-speech  
- **MoviePy & FFmpeg** ‚Äì Video editing  
- **OpenCV** ‚Äì Panel detection  

---

## üìö Documentation

Full technical documentation available in `/docs/`:
- [Architecture](docs/ARCHITECTURE.md)
- [API Reference](docs/API_REFERENCE.md)
- [Config Guide](docs/CONFIG_GUIDE.md)
- [Deployment Guide](docs/DEPLOYMENT.md)

---

> ‚ÄúLet the AI tell your favorite stories ‚Äî one chapter at a time.‚Äù üéôÔ∏è  
> _Created with ‚ù§Ô∏è by the AI Manhwa Dubbing Team_
